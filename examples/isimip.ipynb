{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import hvplot.xarray\n",
    "import numpy as np\n",
    "import scipy.stats\n",
    "import xarray as xr\n",
    "\n",
    "import climepi\n",
    "import climepi.climdata as climdata\n",
    "import climepi.epimod as epimod"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ds_clim = climdata.get_example_dataset(\"isimip_london\").sel(\n",
    "    {\"scenario\": [\"ssp126\", \"ssp370\", \"ssp585\"]}\n",
    ")\n",
    "ds_clim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ds_clim_ym = ds_clim.climepi.yearly_average()\n",
    "ds_clim_ym.climepi.plot_time_series(\"temperature\", by=[\"scenario\"])\n",
    "# ds_clim.isel(time=ds_clim.time.dt.year==2100).climepi.plot_time_series(\"temperature\", color=\"r\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_vars = ds_clim_ym.climepi.get_non_bnd_data_vars()\n",
    "poly_coeff_data_vars = [data_var + \"_polyfit_coefficients\" for data_var in data_vars]\n",
    "data_var_mapping = dict(zip(poly_coeff_data_vars, data_vars))\n",
    "fitted_polys = ds_clim_ym[data_vars].polyfit(dim=\"time\", deg=4, full=True)\n",
    "ds_clim_ym_fit = (\n",
    "    xr.polyval(\n",
    "        coord=ds_clim_ym.time,\n",
    "        coeffs=fitted_polys[poly_coeff_data_vars],\n",
    "    )\n",
    "    .rename(data_var_mapping)\n",
    "    .squeeze(\"realization\", drop=True)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fitted_polys"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ds_clim_ym_fit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "p1 = ds_clim_ym_fit.squeeze().climepi.plot_time_series(\"temperature\", by=[\"scenario\"])\n",
    "p2 = ds_clim_ym.squeeze().climepi.plot_time_series(\"temperature\", by=[\"scenario\"])\n",
    "p1 * p2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "variance_internal = (ds_clim_ym - ds_clim_ym_fit).var()\n",
    "variance_internal.load()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "variance_model = ds_clim_ym_fit.var(dim=\"model\").mean(dim=\"scenario\")\n",
    "variance_model.load()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "variance_scenario = ds_clim_ym_fit.mean(dim=\"model\").var(dim=\"scenario\")\n",
    "variance_scenario.load()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "check = ds_clim_ym_fit.var(dim=[\"model\", \"scenario\"]) - (\n",
    "    variance_model + variance_scenario\n",
    ")\n",
    "check.load()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ds_variances = xr.concat(\n",
    "    [variance_internal, variance_scenario, variance_model],\n",
    "    dim=xr.Variable(\"variance_type\", [\"internal\", \"scenario\", \"model\"]),\n",
    "    coords=\"minimal\",\n",
    ")\n",
    "ds_variances"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_variance_area_plot(_ds_variance, var, proportions=False):\n",
    "    if proportions:\n",
    "        _ds_variance = _ds_variance / _ds_variance.sum(dim=\"variance_type\")\n",
    "    ds_new = xr.Dataset(\n",
    "        {\n",
    "            \"internal\": _ds_variance[var].sel(variance_type=\"internal\", drop=True),\n",
    "            \"scenario\": _ds_variance[var].sel(variance_type=\"scenario\", drop=True),\n",
    "            \"model\": _ds_variance[var].sel(variance_type=\"model\", drop=True),\n",
    "        }\n",
    "    )\n",
    "    return ds_new.squeeze().hvplot.area(\n",
    "        x=\"time\", y=[\"scenario\", \"model\", \"internal\"], group_label=\"Uncertainty type\"\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "make_variance_area_plot(ds_variances, \"temperature\", proportions=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_plume_plot(\n",
    "    _ds,\n",
    "    _ds_fit,\n",
    "    _ds_variances,\n",
    "    var,\n",
    "    conf_level=90,\n",
    "    scenario_baseline=None,\n",
    "    model_baseline=None,\n",
    "):\n",
    "    if scenario_baseline == \"mean\" and model_baseline == \"mean\":\n",
    "        da_baseline = _ds_fit[var].mean(dim=[\"model\", \"scenario\"])\n",
    "        da_fit_scenario_model_baseline = da_baseline\n",
    "        da_fit_scenario_baseline_model_mean = da_baseline\n",
    "    elif scenario_baseline == \"mean\":\n",
    "        raise ValueError(\n",
    "            \"If scenario_baseline is 'mean', model_baseline must be 'mean'\"\n",
    "        )\n",
    "    elif model_baseline == \"mean\":\n",
    "        da_baseline = _ds_fit[var].sel(scenario=scenario_baseline).mean(dim=\"model\")\n",
    "        da_fit_scenario_model_baseline = da_baseline\n",
    "        da_fit_scenario_baseline_model_mean = da_baseline\n",
    "    else:\n",
    "        da_baseline = _ds[var].sel(scenario=scenario_baseline, model=model_baseline)\n",
    "        da_fit_scenario_model_baseline = _ds_fit[var].sel(\n",
    "            scenario=scenario_baseline, model=model_baseline\n",
    "        )\n",
    "        da_fit_scenario_baseline_model_mean = (\n",
    "            _ds_fit[var].sel(scenario=scenario_baseline).mean(dim=\"model\")\n",
    "        )\n",
    "    da_variances = _ds_variances[var]\n",
    "    da_std_internal = np.sqrt(da_variances.sel(variance_type=\"internal\"))\n",
    "    if scenario_baseline == \"mean\":\n",
    "        da_std_internal_model = np.sqrt(\n",
    "            da_variances.sel(variance_type=[\"internal\", \"model\"]).sum(\n",
    "                dim=\"variance_type\"\n",
    "            )\n",
    "        )\n",
    "    else:\n",
    "        da_std_internal_model = np.sqrt(\n",
    "            _ds_fit[var].sel(scenario=scenario_baseline).var(dim=\"model\")\n",
    "            + da_variances.sel(variance_type=\"internal\")\n",
    "        )\n",
    "    z = scipy.stats.norm.ppf(0.5 + conf_level / 200)\n",
    "    ds_internal = xr.Dataset(\n",
    "        {\n",
    "            \"low\": da_fit_scenario_model_baseline - z * da_std_internal,\n",
    "            \"high\": da_fit_scenario_model_baseline + z * da_std_internal,\n",
    "        }\n",
    "    )\n",
    "    ds_model = xr.Dataset(\n",
    "        {\n",
    "            \"low\": da_fit_scenario_baseline_model_mean - z * da_std_internal_model,\n",
    "            \"high\": da_fit_scenario_baseline_model_mean + z * da_std_internal_model,\n",
    "        }\n",
    "    )\n",
    "    da_fit_model_scenario_mean = _ds_fit[var].mean(dim=[\"model\", \"scenario\"])\n",
    "    da_std_internal_model_scenario = np.sqrt(da_variances.sum(dim=\"variance_type\"))\n",
    "    ds_scenario = xr.Dataset(\n",
    "        {\n",
    "            \"low\": da_fit_model_scenario_mean - z * da_std_internal_model_scenario,\n",
    "            \"high\": da_fit_model_scenario_mean + z * da_std_internal_model_scenario,\n",
    "        }\n",
    "    )\n",
    "    p_baseline = da_baseline.hvplot.line(color=\"k\", label=\"Baseline\")\n",
    "    p_internal = ds_internal.hvplot.area(x=\"time\", y=\"low\", y2=\"high\", label=\"Internal\")\n",
    "    p_model = ds_model.hvplot.area(x=\"time\", y=\"low\", y2=\"high\", label=\"Model\")\n",
    "    p_scenario = ds_scenario.hvplot.area(x=\"time\", y=\"low\", y2=\"high\", label=\"Scenario\")\n",
    "    return p_scenario * p_model * p_internal * p_baseline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scenario_baseline = \"mean\"\n",
    "model_baseline = \"mean\"\n",
    "# scenario_baseline = \"ssp370\"\n",
    "# model_baseline = \"gfdl-esm4\"\n",
    "make_plume_plot(\n",
    "    ds_clim_ym.squeeze(),\n",
    "    ds_clim_ym_fit.squeeze(),\n",
    "    ds_variances.squeeze(),\n",
    "    \"temperature\",\n",
    "    conf_level=90,\n",
    "    scenario_baseline=scenario_baseline,\n",
    "    model_baseline=model_baseline,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scenario_baseline = \"mean\"\n",
    "model_baseline = \"mean\"\n",
    "# scenario_baseline = \"ssp370\"\n",
    "# model_baseline = \"gfdl-esm4\"\n",
    "make_plume_plot(\n",
    "    ds_clim_ym.squeeze(),\n",
    "    ds_clim_ym_fit.squeeze(),\n",
    "    ds_variances.squeeze(),\n",
    "    \"precipitation\",\n",
    "    conf_level=90,\n",
    "    scenario_baseline=scenario_baseline,\n",
    "    model_baseline=model_baseline,\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "climepi",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
